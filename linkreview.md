# LinkReview

- Here we have collect info about all the works that may be useful for writing our paper
- We divide these works by topic in order to structure them
- Each of the contributors is responsible for their part of the work, as specified in the table

> [!NOTE]
> This review table will be updated, so it is not a final version

| Topic | Title | Year | Authors | Paper | Code | Summary |
| :--- | :--- | ---: | :--- | :--- | :--- | :--- |
| Datasets with simultaneous fMRI-EEG signals <br> [@kisnikser](https://github.com/kisnikser) | An open-access dataset of naturalistic viewing using simultaneous EEG-fMRI | 2023 | Qawi K. Telesford et al. | [scientific data](https://www.nature.com/articles/s41597-023-02458-8) | [GitHub](https://github.com/NathanKlineInstitute/NATVIEW_EEGFMRI) | Recordings of **simultaneous** fRMI-EEG from 22 individuals across various visual and naturalistic stimulus. Visual tasks: flickering checkerboard, visual paradigm Inscapes, several short video movies. |
|      | Multisubject, multimodal face processing | 2024 | Daniel G Wakeman et al. | [scientific data](https://www.nature.com/articles/sdata20151) | [OpenNeuro](https://openneuro.org/datasets/ds000117/versions/1.0.6) | Containts **simultaneous** fMRI-EEG data for 16 participants. Visual stimuli: perceptual task on pictures of familiar, unfamiliar and scrambled faces during two visits to the laboratory. |
|      | Open multimodal iEEG-fMRI dataset from naturalistic stimulation with a short audiovisual film | 2022 | Julia Berezutskaya et al. | [scientific data](https://www.nature.com/articles/s41597-022-01173-0) | [GitHub #1](https://github.com/UMCU-RIBS/ieeg-fmri-dataset-validation), [GitHub #2](https://github.com/UMCU-RIBS/ieeg-fmri-dataset-quickstart) | Contains fMRI-EEG data for 51 participants, but non-simultaneous. Short audiovisual film stimulus, around 6 minutes of Pippi Longstocking. |
|      | Simultaneous EEG and functional MRI data during rest and sleep from humans | 2023 | Yameng Gu et al. | [Data in Brief](https://www.sciencedirect.com/science/article/pii/S2352340923001774) | [Download](https://openneuro.org/datasets/ds003768/versions/1.0.11) | Investigate spontaneous brain activity across distinct brain states. Contains fMRI-EEG data from 33 participants during the resting state and sleep. No visual stimuli. |
|      | Simultaneous and independent electroencephalography and magnetic resonance imaging: A multimodal neuroimaging dataset | 2023 | Jonathan Gallego-Rudolf et al. | [Data in Brief](https://www.sciencedirect.com/science/article/pii/S2352340923007461) | [Download](https://data.mendeley.com/datasets/crhybxpdy6/2) | Contains EEG and MRI data from 20 males performing eyes-open and eyes-closed tasks, with EEG recorded both inside and outside the MRI scanner. Total approximately 28 sessions. Not suitable for us, it is for studying the effect of simultaneously taking sensor readings. No visual stimuli. |   
|      | Le Petit Prince Hong Kong (LPPHK): Naturalistic fMRI and EEG data from older Cantonese speakers | 2024 | Mohammad Momenian et al. | [bioRxiv](https://www.biorxiv.org/content/10.1101/2024.04.24.590842v1) | [OpenNeuro](https://openneuro.org/datasets/ds004718/versions/1.1.0) | Sessions of fMRI and EEG for 52 participants. Audio stimuli: The Little Prince in Cantonese for approximately 20 minutes. Non-simultaneous. | 
|      | Multimodal single-neuron, intracranial EEG, and fMRI brain responses during movie watching in human patients | 2024 | Umit Keles et al. | [scientific data](https://www.nature.com/articles/s41597-024-03029-1) | [GitHub](https://github.com/OpenNeuroDatasets/ds004798), [OpenNeuro](https://openneuro.org/datasets/ds004798/versions/1.0.5) | Contains fMRI-EEG data for 20 participants. Visual stimuli: 8-min long excerpt from the video "Bang! You're Dead", arecognition memory test for movie content. |
| Methods using fMRI <br> [@DorinDaniil](https://github.com/DorinDaniil) | Natural scene reconstruction from fMRI signals using generative latent diffusion | 2023 | Furkan Ozcelik et al. | [arXiv](https://arxiv.org/abs/2303.05334) | [GitHub](https://github.com/ozcelikfu/brain-diffuser) | Reconstruct a low-quality image, using the pre-trained VDVAE. Enhance the fidelity of the generated image with a pre-trained diffusion model (e.g., SD 1.5), using image and text embeddings as a context for generation process. Use sklearn ridge regression as an fMRI encoder |
|      | fMRI-based Decoding of Visual Information from Human Brain Activity: A Brief Review | 2021 | Shuo Huang et al. | [Springer Link](https://link.springer.com/article/10.1007/s11633-020-1263-y) | - | Analyze architectures. The diagrams show that at the time of 2019, generative architectures are actively used. |
|      | Cinematic Mindscapes: High-quality Video Reconstruction from Brain Activity | 2023 | Zijiao Chen et al. | [arXiv](https://arxiv.org/abs/2305.11675) | [GitHub](https://github.com/jqin4749/MindVideo), [Website](https://www.mind-video.com/) | Decoding video sequences using fMRI data. SC-MBM encoder for fMRI. |
|      | High-resolution image reconstruction with latent diffusion models from human brain activity | 2023 | Yu Takagi et al. | [arXiv](https://arxiv.org/abs/2306.11536) | [GitHub](https://github.com/yu-takagi/StableDiffusionReconstruction) | |
| Methods using EEG <br> [@sem-k32](https://github.com/sem-k32) | Visual Decoding and Reconstruction via EEG Embeddings with Guided Diffusion | 2024 | Dongyang Li et al. | [arXiv](https://arxiv.org/abs/2403.07721v5) | [GitHub](https://github.com/dongyangli-del/EEG_Image_decode)  | EEG encoder = Transformer -> CNN (for spatiotemp. dependencies) -> MLP; EEG context vector is used to reconstruct image CLIP-vector. The latter is used in diffusion model to gen images |
|      | NeuroGAN: image reconstruction from EEG signals via an attention-based GAN | 2022 | Rahul Mishra et al. | [Springer Link](https://link.springer.com/article/10.1007/s00521-022-08178-1) | - | CNN encoder for EEG incorporated into GAN's generator. $$ Loss = Loss_{\text{GAN}} + Loss_{\text{image classification}} + Loss_{\text{perceptial loss}} $$ |
|      | EEG2IMAGE: Image Reconstruction from EEG Brain Signals | 2023 | Prajwal Singh et al. | [arXiv](https://arxiv.org/abs/2302.10121) | [GitHub](https://github.com/prajwalsingh/EEG2Image) | Individual EEG feature extractor (LSTM, constastive learning) + conditioned GAN for image generation |
|      | Image Reconstruction from Electroencephalography Using Latent Diffusion | 2024 | Teng Fei et al. | [arXiv](https://arxiv.org/abs/2404.01250) | [GitHub](https://github.com/desa-lab/EEG-Image-Reconstruction) |   info-gypsy   |
|      | Image classification and reconstruction from low‑density EEG | 2024 | Sven Guenther et. al. | [Nature Reports](https://www.nature.com/articles/s41598-024-66228-1.pdf) |  |   compare diffrent EEG-encoders for classification/reconstruction (diffusion conditioning) tasks   |
|      | DCAE: A dual conditional autoencoder framework for the reconstruction from EEG into image | 2023 | Hong Zeng et. al. | [ELSEVIER](https://www.sciencedirect.com/science/article/pii/S1746809422008941/pdfft?casa_token=z0Oo8Ta4XzYAAAAA:dWKusVo-7Q2LnOswCxTnUmq9dO0mYcmEEsoKyRxARZ4AiWUPeyRHB3Knk7gnKn5Fn7v1BJvAdQ&md5=9c72d87f28b37ae7865377f44dbff021&pid=1-s2.0-S1746809422008941-main.pdf) |  |   CNN EEG encoder to approxiamate DenseNet image vector + **UNet** architecture to generate image  |
|      | Photorealistic reconstruction of visual texture from EEG signals | 2021 | Suguru Wakita et. al. | [Frontiers](https://www.frontiersin.org/articles/10.3389/fncom.2021.754587/pdf) |  | uses VAE model. Input is image + EEG, proccessed separetely and then fused; output is image + EEG, separetely processed |
| SOTA fMRI encoders <br> [@DorinDaniil](https://github.com/DorinDaniil) |     |     |     |     |     |     |
|      |      |      |      |      |      |      |
| SOTA EEG encoders <br> [@sem-k32](https://github.com/sem-k32) |     |     |     |     |     |     |
|      |   EEGNet: a compact convolutional neural network for EEG-based brain–computer interfaces   |   2018   |   Vernon J Lawhern et. al.   |   [IOPScience](https://iopscience.iop.org/article/10.1088/1741-2552/aace8c)   |   -  |   CNN-model with decoupled time and space convolutions   |
|      |   TSception:A Deep Learning Framework for Emotion Detection Using EEG   |   2020   |   Yi Ding et. al.   |   [IEEE](https://ieeexplore.ieee.org/document/9206750)   |      |   another CNN-model   |
| SOTA methods for image generation <br> [@2001092236](https://github.com/2001092236) |     |     |     |     |     |     |
|      |  Versatile Diffusion: Text, Images and Variations All in One Diffusion Model    |   2024   | Xingqian Xl et. al.     |   [arXiv](https://arxiv.org/pdf/2211.08332)   |  [GitHub](https://github.com/SHI-Labs/Versatile-Diffusion)    |    based on image and/or text generates image and text. Uses VAE (input->latent), context encoders (different input modalities into one embedding space) and Diffusion Model|
|      |    High-resolution image reconstruction with latent diffusion models from human brain activity	  |   2023 | Yu Takagi et al.   |  [arXiv](https://arxiv.org/abs/2306.11536)    |   [GitHub](https://github.com/yu-takagi/StableDiffusionReconstruction)   |  CLIP for encoding text, LDM for conditional generation. They train encoder (Image+Text->fMRI) and decoder (fMRI->image). Use freezed NNs. Models: LDM, CLIP
|      |   Efficient-VDVAE: Less is more   | 2022  | Louay Hazami et. al. | [aeXiv](https://arxiv.org/abs/2203.13751)    |  [github](https://github.com/Rayhane-mamah/Efficient-VDVAE)    | (about VDVAE): uses hierarchical VAE (very deep), no latent space collapse.  Train weights available (see github) |
|      |      |      |      |      |      |      |
